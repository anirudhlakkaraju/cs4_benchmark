{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT API calls for Direction 2 Constraint generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an English writing expert and you need to set hard essay prompts for the genre of Relistic Fiction. Your aim is to generate extremely hard constraints that make the essay writing very challenging. \n",
    "\n",
    "An essay prompt is defined as a main Instruction + Constraints. You will be given an Instruction as an input and you should generate more complex constraints that can be added to the Instruction which together make up the essay prompt. \n",
    "\n",
    "Give me a numbered list of EXACTLY 40 CONSTRAINTS.\n",
    "\n",
    "The constraints you generate can be plot, style or format related. The constraints should be complex and creative so you may come up with constraints that can differ from the main topic of the Instruction. But keep them realistic enough and not too contradictory ensure that it's possible to write a high quality story. \n",
    "\n",
    "It should NOT require any specific domain knowledge to understand the constraints. DO NOT INCLUDE COMPLICATED VOCABULARY OR ASK FOR ANY POETRY RELATED FORMAT in your constriants. Make your constraints such that a flow (if any) in a story can be maintained.\n",
    "\n",
    "The constraints should be clear and atomic, that is, if a constraint can be decomposed into multiple sub constraints, list all of them separately. DO NOT REPEAT CONSTRAINTS. JUST GIVE ONLY THE CONSTRAINT IN EACH LiST ITEM.\n",
    "\"\"\"\n",
    "\n",
    "prompt_examples = \"\"\"Here are some examples with 10 constraint outputs, for your reference -\n",
    "\n",
    "Input - Write a story that follows the journey of a professional working woman named Rachel Michelle.\n",
    "Output - \n",
    "1. Rachel is single, has two kids she is supporting through high school.\n",
    "2. Rachel is considering leaving her corporate job to become an entrepreneur. \n",
    "3. The story should detail the steps she takes to create a life plan and make the leap.\n",
    "4. Highlight her success as an entrepreneur with five employees.\n",
    "5. The book should be written in a motivational and engaging style.\n",
    "6. Incorporate practical and mental wellness strategies that helped her achieve her goals.\n",
    "7. Explore the complex relationship between her and her growing kids.\n",
    "8. The story should be a lesson in holistic wellness and life coaching.\n",
    "9. The story should cater to a young audience.\n",
    "10. Write the story in 8 paragraphs or less.\n",
    "\n",
    "Input - Write a story about the incident of two friend's day out gone wrong.\n",
    "Output - \n",
    "1. One of the friends must have a secret that is revealed during the day out.\n",
    "2. One of the friends must have a phobia that becomes a central theme in the story.\n",
    "3. Maintain a casual tone overall but create tension when required to keep readers engaged. \n",
    "4. Involve their pet parrot in the plot. \n",
    "5. The story must contain an unexpected plot twist.\n",
    "6. The friends must communicate through handwritten notes for a part of the story.\n",
    "7. The story must include a mysterious stranger who impacts their day.\n",
    "8. The setting of the story must change at least two times.\n",
    "9. The climax of the story must involve a natural disaster.\n",
    "10. The story must end with a cliffhanger that leaves the readers guessing about the fate of the friends.\n",
    "\n",
    "\"\"\"\n",
    "user_input = \"\"\"\n",
    "Input - {}\n",
    "Output -\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = system_prompt + prompt_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup OpenAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def chat(instruction, model=\"gpt-3.5-turbo\", system_prompt=system_prompt, log=False):\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":system_prompt},\n",
    "            {\"role\": \"user\", \"content\":user_input.format(instruction)},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    log_usage(tokens=response.usage.total_tokens, model=model)\n",
    "\n",
    "    if log:\n",
    "        print(\"Total tokens used: \", response.usage.total_tokens)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def log_usage(tokens, model):\n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "\n",
    "    # Write the date-time and tokens used to the file\n",
    "    with open(\"api_usage.txt\", \"a\") as file:\n",
    "        file.write(f\"{model} {current_time} : {tokens}\\n\")\n",
    "\n",
    "def total_usage():\n",
    "    model_tokens = {}\n",
    "    model_prices = {\"gpt-3.5-turbo\": 0.0015, \"gpt-4-turbo\": 0.03}\n",
    "    \n",
    "    with open(\"api_usage.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.split(\" \")\n",
    "            if len(parts) >= 4:\n",
    "                model_name = parts[0]\n",
    "                tokens_str = parts[-1].strip()\n",
    "                tokens = int(tokens_str)\n",
    "                if model_name in model_tokens:\n",
    "                    model_tokens[model_name] += tokens\n",
    "                else:\n",
    "                    model_tokens[model_name] = tokens\n",
    "    \n",
    "    total_cost = 0\n",
    "    for model, tokens in model_tokens.items():\n",
    "        cost = (tokens * model_prices[model]) / 1000\n",
    "        total_cost += cost\n",
    "        print(f\"Total tokens used for {model}: {tokens}\")\n",
    "        print(f\"\\nTotal cost for {model}: {cost}$\")\n",
    "    \n",
    "    print(f\"\\nTotal cost so far: {total_cost}$\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "def get_instructions():\n",
    "\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(\"../Data/input_instructions.xlsx\")\n",
    "\n",
    "    instructions = [list(row.values()) for row in df.to_dict(orient='records')]\n",
    "    \n",
    "    return instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_constraints(model):\n",
    "    instructions = get_instructions()\n",
    "\n",
    "    df = pd.read_excel('../Data/input_instructions.xlsx')\n",
    "\n",
    "    dfs_to_concat = []\n",
    "\n",
    "    i = 0\n",
    "    for instruction in instructions:\n",
    "        i+=1\n",
    "        if i <30:\n",
    "            continue\n",
    "        response = chat(instruction=instruction[0], model=model, log=True)\n",
    "        # print(response.choices[0].message.content)\n",
    "        new_row = {\n",
    "            'Instruction': instruction[0],\n",
    "            'Category': instruction[1],\n",
    "            'Constraints': response.choices[0].message.content\n",
    "        }\n",
    "        new_df = pd.DataFrame([new_row])\n",
    "\n",
    "        dfs_to_concat.append(new_df)\n",
    "        i += 1\n",
    "    # Concatenate all DataFrames in the list\n",
    "    df = pd.concat([df] + dfs_to_concat, ignore_index=True)\n",
    "\n",
    "    df.to_excel('../Data/constraints_dir2_gpt4_40_final.xlsx', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used:  1490\n",
      "Total tokens used:  1428\n",
      "Total tokens used:  1605\n",
      "Total tokens used:  1556\n",
      "Total tokens used:  1414\n",
      "Total tokens used:  1380\n",
      "Total tokens used:  1455\n",
      "Total tokens used:  1442\n",
      "Total tokens used:  1305\n",
      "Total tokens used:  1482\n",
      "Total tokens used:  1436\n",
      "Total tokens used:  1376\n",
      "Total tokens used:  1324\n",
      "Total tokens used:  1397\n",
      "Total tokens used:  1360\n",
      "Total tokens used:  1520\n",
      "Total tokens used:  1432\n",
      "Total tokens used:  1473\n",
      "Total tokens used:  1487\n",
      "Total tokens used:  1463\n"
     ]
    }
   ],
   "source": [
    "generate_constraints(\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used for gpt-3.5-turbo: 43194\n",
      "\n",
      "Total cost for gpt-3.5-turbo: 0.064791$\n",
      "\n",
      "Total cost so far: 0.064791$\n"
     ]
    }
   ],
   "source": [
    "total_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_system_prompt = \"\"\"You are an expert story writer and are required to write a story based on the user provided instruction and constraints.\n",
    "IMPORTANT - Satisfy all the constraints while sticking to the given word limit. Do not go beyond the word limit.\n",
    "\"\"\"\n",
    "\n",
    "def generate_stories(model=\"chatgpt-3.5-turbo\"):\n",
    "    df = pd.read_excel('../Data/constraints_dir2_gpt4_40_final2.xlsx')\n",
    "\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        user_prompt = f\"Instruction - {row['instruction']}\\nConstraints - {row['constraints']}\"\n",
    "        \n",
    "        # Feed user prompt and system prompt into chat method\n",
    "        response = client.chat.completions.create(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":story_system_prompt},\n",
    "                {\"role\": \"user\", \"content\":user_prompt},\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract generated story from response\n",
    "        generated_story = response.choices[0].message.content\n",
    "        \n",
    "        # Append generated story to the DataFrame\n",
    "        df.at[index, 'final_prompt'] = user_prompt\n",
    "        df.at[index, 'generated_story'] = generated_story\n",
    "\n",
    "        # if i==1:\n",
    "        #     break\n",
    "            \n",
    "        # i += 1\n",
    "    \n",
    "    # print(df.head())\n",
    "    # return\n",
    "\n",
    "\n",
    "    # Save the updated DataFrame back to the original CSV file\n",
    "    df.to_excel('../Data/constraints_dir2_gpt4_40_final2.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stories(\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "696",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
